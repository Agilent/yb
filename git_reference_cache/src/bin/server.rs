use std::io;
use std::sync::Arc;
use futures::{future, prelude::*};
use tokio::signal;
use tarpc::{
    server::{self, incoming::Incoming, Channel},
    tokio_serde::formats::Json,
};
use git_reference_cache::cache::ConcurrentGitCache;
use git_reference_cache::server::GitReferenceCacheServer;
use git_reference_cache::service::Service;

#[tokio::main]
async fn main() -> io::Result<()> {
    let cache = Arc::new(ConcurrentGitCache::new());

    // JSON transport is provided by the json_transport tarpc module. It makes it easy
    // to start up a serde-powered json serialization strategy over TCP.
    let mut listener = tarpc::serde_transport::tcp::listen("127.0.0.1:1234", Json::default).await?;
    listener.config_mut().max_frame_length(usize::MAX);
    let server = listener
        // Ignore accept errors.
        .filter_map(|r| future::ready(r.ok()))
        .map(server::BaseChannel::with_defaults)
        // Limit channels to 1 per IP.
        .max_channels_per_key(1, |t| t.transport().peer_addr().unwrap().ip())
        // serve is generated by the service attribute. It takes as input any type implementing
        // the generated World trait.
        .map(|channel| {
            let server = GitReferenceCacheServer::new(cache.clone());
            channel.execute(server.serve())
        })
        // Max 10 channels.
        .buffer_unordered(10)
        .for_each(|_| async {});

    tokio::select! {
        _ = server => { }
        _ = signal::ctrl_c() => {
            // The shutdown signal has been received.
            eprintln!("shutting down");
        }
    }

    Ok(())
}
