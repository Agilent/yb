use std::io;
use std::sync::Arc;
use clap::Parser;
use futures::{future, prelude::*};
use tokio::signal;
use tarpc::{
    server::{self, Channel},
    tokio_serde::formats::Json,
};
use concurrent_git_pool::pool::Pool;
use concurrent_git_pool::server::Server;
use concurrent_git_pool::service::Service;

#[derive(Parser)]
struct Args {
    #[arg(short, long)]
    port: u16,
}

#[tokio::main]
async fn main() -> io::Result<()> {
    let args = Args::parse();

    let cache = Arc::new(Pool::new());

    // JSON transport is provided by the json_transport tarpc module. It makes it easy
    // to start up a serde-powered json serialization strategy over TCP.
    let mut listener = tarpc::serde_transport::tcp::listen(format!("127.0.0.1:{}", args.port), Json::default).await?;
    listener.config_mut().max_frame_length(usize::MAX);
    let server = listener
        // Ignore accept errors.
        .filter_map(|r| future::ready(r.ok()))
        .map(server::BaseChannel::with_defaults)
        // serve is generated by the service attribute. It takes as input any type implementing
        // the generated World trait.
        .map(|channel| {
            let server = Server::new(cache.clone());
            channel.execute(server.serve())
        })
        // Max 10 channels.
        .buffer_unordered(10)
        .for_each(|_| async {});

    tokio::select! {
        _ = server => { }
        _ = signal::ctrl_c() => {
            // The shutdown signal has been received.
            eprintln!("shutting down");
        }
    }

    Ok(())
}
